# -*- coding: utf-8 -*-
"""Moviescope.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LS8eM6Kf3-Uh0q4jpR31ZY1-cB6EUmAh
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
import numpy as np
import pickle
import datetime
import os

default_model_name = 'vgg16'
frameWidth = 224
frameHeight = 224

def load_pkl(pklName, verbose=True):
  if verbose:
      print ("Loading data from data/{0}.p".format(pklName))
  with open(pklName, 'rb') as f:
      u = pickle._Unpickler(f)
      #u.encoding = 'latin1'
      p = u.load()
      return p

def spatial_model(number_of_classes=2):
  """Classification layers here."""
  model1 = Sequential()
  model1.add(Dense(2048, input_dim=4096, activation='relu'))
  model1.add(Dropout(0.25))
  model1.add(Dense(256, activation='relu'))
  model1.add(Dropout(0.5))
  model1.add(Dense(64, activation='relu'))
  model1.add(Dense(number_of_classes, activation='softmax'))
  return model1

def train_classifier(genres=['romance', 'horror', 'action'], model_name=default_model_name):
  num_of_classes = len(genres)
  #trainingData = []
  #trainingLabels = []
  trainingData = load_pkl('./data/training_data_235.p')
  trainingLabels = load_pkl('./data/training_labels_235.p')
  trainingData = np.array(trainingData)
  trainingLabels = np.array(trainingLabels)
  print (trainingData.shape)
  print (trainingLabels.shape)

  model = spatial_model(num_of_classes)

  initial_learning_rate = 0.01
  lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
      initial_learning_rate, decay_steps=50, decay_rate=0.96, staircase=False
  )

  def loss(labels, logits):
    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits)

  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=initial_learning_rate), loss=loss,metrics='accuracy')
  #model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

  """Start training"""
  batch_size = 5
  nb_epoch = 100

  checkpoint_dir = './data/ckpt_set1'
  checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt_{epoch}")
  logdir = os.path.join("logdir_set1", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))

  checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_prefix,
    save_weights_only=True,verbose=2)


  history = model.fit(trainingData, trainingLabels, batch_size=batch_size, epochs=nb_epoch,callbacks=[checkpoint_callback])
  modelOutPath ='./data/models/spatial'+model_name+'_'+str(num_of_classes)+"g_bs"+str(batch_size)+"_ep"+str(nb_epoch)+".h5"
  model.save(modelOutPath)
  print( "Model saved at",modelOutPath)

train_classifier(genres=['Action','Comedy','Drama','Fantasy','Horror_Mystery','Romance','Thriller'])
